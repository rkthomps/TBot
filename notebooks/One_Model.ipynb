{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c638182-9fa0-4859-97d9-147982a67acc",
   "metadata": {},
   "source": [
    "# This is my first attempt at constructing a single model to conduct predictictions on stock market technicals. There is probably a more mature version on dev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uZsRSKdbSkRL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZsRSKdbSkRL",
    "outputId": "f23f27c9-948e-4edb-f0bd-c87e60261cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/content/drive/MyDrive/WINTER2022/Data40123/TBot/', '', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "preproc_loc = '/content/drive/MyDrive/WINTER2022/Data40123/TBot/'\n",
    "if preproc_loc not in sys.path:\n",
    "  sys.path.insert(0, preproc_loc)\n",
    "  print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0cbdb-2f9e-4967-a8c4-ad87c15eb1bd",
   "metadata": {
    "id": "2dc0cbdb-2f9e-4967-a8c4-ad87c15eb1bd"
   },
   "outputs": [],
   "source": [
    "## Trains One LSTM model on all Companies in SNP500\n",
    "import tensorflow as tf\n",
    "from W_Preproc import Weekly_Preprocessor as WP\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CtKm1fbvSNEW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtKm1fbvSNEW",
    "outputId": "dab640f4-9a60-4f9b-a6e7-d0d8f50b5251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d2cde-0e25-40e8-8c18-c386231d48b0",
   "metadata": {
    "id": "328d2cde-0e25-40e8-8c18-c386231d48b0"
   },
   "outputs": [],
   "source": [
    "\n",
    "WP_dict = {\n",
    "    'train': WP(40, 1970, 2000),\n",
    "    'val': WP(40, 2001, 2009),\n",
    "    'test': WP(40, 2010, 2021),\n",
    "}\n",
    "\n",
    "# Creates a Generator that will be used by tensorflow to get data\n",
    "# Takes as input a WeeklyPreprocessor Object\n",
    "def gen_data(wp_num, batch_size):\n",
    "    global WP_dict\n",
    "    wp_name = {0: 'train', 1: 'val', 2: 'test'}[wp_num]\n",
    "    wp = WP_dict[wp_name]\n",
    "    while True:\n",
    "        n_examples = 0\n",
    "        xs = []\n",
    "        ys = []\n",
    "        while n_examples < batch_size:\n",
    "          result = wp.get_next_week()\n",
    "          if result is not None:\n",
    "              x, y, prices, companies, b_date, s_date, cur_week = result\n",
    "              xs.append(x)\n",
    "              ys.append(y[:, None])\n",
    "          else:\n",
    "              x, y, prices, companies, b_date, s_date, cur_week = wp.get_next_week()\n",
    "              xs.append(x)\n",
    "              ys.append(y[:, None])\n",
    "          n_examples += 1\n",
    "        yield np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)[:, 0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7681ae-03fd-48af-a66d-1b82cd2680c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4d7681ae-03fd-48af-a66d-1b82cd2680c2",
    "outputId": "80a428aa-acb3-4106-bab5-d4f6bfb02aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 11s 118ms/step - loss: 2.2414 - val_loss: 2.0389\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.9278 - val_loss: 1.7711\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.6855 - val_loss: 1.5992\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.5257 - val_loss: 1.4772\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 1.4109 - val_loss: 1.3780\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.3156 - val_loss: 1.2910\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.2311 - val_loss: 1.2113\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 1.1545 - val_loss: 1.1381\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 1.0842 - val_loss: 1.0695\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 1.0192 - val_loss: 1.0063\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 5s 91ms/step - loss: 0.9579 - val_loss: 0.9321\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.8882 - val_loss: 0.8656\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.8261 - val_loss: 0.8055\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.7694 - val_loss: 0.7505\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.7175 - val_loss: 0.7001\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.6699 - val_loss: 0.6537\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.6261 - val_loss: 0.6111\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 5s 91ms/step - loss: 0.5858 - val_loss: 0.5719\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.5487 - val_loss: 0.5356\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.5145 - val_loss: 0.5024\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 6s 90ms/step - loss: 0.4812 - val_loss: 0.4666\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.4474 - val_loss: 0.4342\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.4170 - val_loss: 0.4048\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.3893 - val_loss: 0.3783\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.3642 - val_loss: 0.3544\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 6s 88ms/step - loss: 0.3412 - val_loss: 0.3324\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.3202 - val_loss: 0.3121\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 6s 87ms/step - loss: 0.3010 - val_loss: 0.2938\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 6s 88ms/step - loss: 0.2834 - val_loss: 0.2766\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 6s 88ms/step - loss: 0.2671 - val_loss: 0.2608\n",
      "Epoch 1/10\n",
      "69/69 [==============================] - 6s 89ms/step - loss: 0.2562 - val_loss: 0.2478\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.2417 - val_loss: 0.2343\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.2285 - val_loss: 0.2210\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 0.2163 - val_loss: 0.2096\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 0.2051 - val_loss: 0.1988\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 0.1946 - val_loss: 0.1889\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.1849 - val_loss: 0.1805\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 0.1759 - val_loss: 0.1705\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 6s 87ms/step - loss: 0.1675 - val_loss: 0.1632\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 6s 86ms/step - loss: 0.1596 - val_loss: 0.1553\n",
      "Epoch 1/10\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 0.1474 - val_loss: 0.1478\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1385 - val_loss: 0.1405\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1304 - val_loss: 0.1331\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1230 - val_loss: 0.1263\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1161 - val_loss: 0.1190\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1096 - val_loss: 0.1133\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.1036 - val_loss: 0.1071\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.0979 - val_loss: 0.1021\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 0.0926 - val_loss: 0.0970\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 0.0877 - val_loss: 0.0916\n",
      "Epoch 1/10\n",
      "96/96 [==============================] - 8s 83ms/step - loss: 0.0827 - val_loss: 0.0859\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 8s 82ms/step - loss: 0.0779 - val_loss: 0.0813\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 8s 82ms/step - loss: 0.0734 - val_loss: 0.0769\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0693 - val_loss: 0.0728\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 8s 80ms/step - loss: 0.0654 - val_loss: 0.0689\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0619 - val_loss: 0.0654\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0586 - val_loss: 0.0621\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0555 - val_loss: 0.0592\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0526 - val_loss: 0.0563\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 8s 81ms/step - loss: 0.0499 - val_loss: 0.0538\n",
      "Epoch 1/10\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.0471 - val_loss: 0.0486\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0453 - val_loss: 0.0470\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0436 - val_loss: 0.0451\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0419 - val_loss: 0.0436\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0403 - val_loss: 0.0420\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0388 - val_loss: 0.0406\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0374 - val_loss: 0.0394\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.0361 - val_loss: 0.0378\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.0336 - val_loss: 0.0355\n",
      "Epoch 1/10\n",
      "72/72 [==============================] - 9s 101ms/step - loss: 0.0323 - val_loss: 0.0395\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 7s 99ms/step - loss: 0.0312 - val_loss: 0.0387\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 7s 101ms/step - loss: 0.0302 - val_loss: 0.0373\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 7s 101ms/step - loss: 0.0292 - val_loss: 0.0366\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0283 - val_loss: 0.0358\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0274 - val_loss: 0.0348\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0265 - val_loss: 0.0341\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0257 - val_loss: 0.0332\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0250 - val_loss: 0.0325\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 7s 100ms/step - loss: 0.0243 - val_loss: 0.0319\n",
      "Epoch 1/10\n",
      "75/75 [==============================] - 6s 86ms/step - loss: 0.0234 - val_loss: 0.0252\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0227 - val_loss: 0.0246\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0221 - val_loss: 0.0239\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0215 - val_loss: 0.0234\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0203 - val_loss: 0.0223\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0193 - val_loss: 0.0211\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 6s 84ms/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 1/10\n",
      "71/71 [==============================] - 6s 86ms/step - loss: 0.0179 - val_loss: 0.0183\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0162 - val_loss: 0.0166\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 6s 86ms/step - loss: 0.0159 - val_loss: 0.0163\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0156 - val_loss: 0.0160\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 6s 85ms/step - loss: 0.0151 - val_loss: 0.0155\n",
      "Epoch 1/10\n",
      "77/77 [==============================] - 7s 86ms/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0141 - val_loss: 0.0160\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0136 - val_loss: 0.0156\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0134 - val_loss: 0.0154\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0133 - val_loss: 0.0154\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 6s 85ms/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 6s 85ms/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0128 - val_loss: 0.0145\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 1/10\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 6s 83ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 1/10\n",
      "76/76 [==============================] - 6s 85ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 2/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 3/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 4/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 5/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 6/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 7/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 8/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 9/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 10/10\n",
      "76/76 [==============================] - 6s 84ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 1/10\n",
      "77/77 [==============================] - 7s 85ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0095 - val_loss: 0.0089\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 6s 84ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 7s 85ms/step - loss: 0.0084 - val_loss: 0.0140\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0080 - val_loss: 0.0137\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0079 - val_loss: 0.0135\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0078 - val_loss: 0.0139\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0078 - val_loss: 0.0133\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0077 - val_loss: 0.0134\n",
      "Epoch 1/10\n",
      "105/105 [==============================] - 8s 81ms/step - loss: 0.0082 - val_loss: 0.0092\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0080 - val_loss: 0.0091\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 8s 79ms/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0076 - val_loss: 0.0086\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 8s 80ms/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0067 - val_loss: 0.0072\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 9s 79ms/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 9s 80ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0057 - val_loss: 0.0080\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 11s 78ms/step - loss: 0.0054 - val_loss: 0.0076\n",
      "Epoch 1/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 2/10\n",
      "135/135 [==============================] - 10s 78ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 3/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 4/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 5/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 6/10\n",
      "135/135 [==============================] - 10s 78ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 7/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 8/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 9/10\n",
      "135/135 [==============================] - 11s 78ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 10/10\n",
      "135/135 [==============================] - 10s 78ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 1/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0054 - val_loss: 0.0067\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 11s 77ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 11s 78ms/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 11s 77ms/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 11s 77ms/step - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 11s 77ms/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 12s 77ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 13s 77ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 13s 77ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 13s 77ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 13s 76ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 13s 77ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 13s 77ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 13s 77ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 13s 76ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 13s 77ms/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 1/10\n",
      "195/195 [==============================] - 15s 78ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 2/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 3/10\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 5/10\n",
      "195/195 [==============================] - 15s 78ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 6/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 7/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 8/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 9/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 1/10\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 2/10\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 3/10\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 4/10\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 7/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 9/10\n",
      "205/205 [==============================] - 16s 76ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 10/10\n",
      "205/205 [==============================] - 16s 77ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 1/10\n",
      "224/224 [==============================] - 18s 81ms/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 17s 78ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 17s 78ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 17s 78ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 17s 77ms/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 17s 77ms/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 17s 76ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 17s 76ms/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 17s 77ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 17s 76ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 1/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "231/231 [==============================] - 18s 76ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "231/231 [==============================] - 18s 78ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 6/10\n",
      "231/231 [==============================] - 18s 78ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 10/10\n",
      "231/231 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "236/236 [==============================] - 18s 77ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 2/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 3/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 4/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 5/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 6/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 7/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 8/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 9/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 10/10\n",
      "236/236 [==============================] - 18s 76ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 1/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 3/10\n",
      "246/246 [==============================] - 19s 77ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 4/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 5/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 6/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 7/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 8/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 9/10\n",
      "246/246 [==============================] - 19s 76ms/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 10/10\n",
      "246/246 [==============================] - 19s 75ms/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 1/10\n",
      "269/269 [==============================] - 20s 75ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 2/10\n",
      "269/269 [==============================] - 20s 75ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 3/10\n",
      "269/269 [==============================] - 20s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 4/10\n",
      "269/269 [==============================] - 20s 75ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 5/10\n",
      "269/269 [==============================] - 20s 75ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 6/10\n",
      "269/269 [==============================] - 20s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 7/10\n",
      "269/269 [==============================] - 20s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 8/10\n",
      "269/269 [==============================] - 21s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 9/10\n",
      "269/269 [==============================] - 21s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 10/10\n",
      "269/269 [==============================] - 20s 76ms/step - loss: 0.0020 - val_loss: 0.0026\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fef1e15f70c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcur_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mcur_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_generator = gen_data(0, 25)\n",
    "val_generator = gen_data(1, 2)\n",
    "cur_x, cur_y = data_generator.__next__()\n",
    "val_x, val_y = val_generator.__next__()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=cur_x.shape[1:]))\n",
    "model.add(tf.keras.layers.LSTM(30, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "model.add(tf.keras.layers.LSTM(10, kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(1e-2)))\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "for i in range(50):\n",
    "    model.fit(cur_x, cur_y, epochs=10, batch_size=20, validation_data=(val_x, val_y))\n",
    "    del cur_x\n",
    "    del cur_y\n",
    "    del val_x\n",
    "    del val_y\n",
    "    cur_x, cur_y = data_generator.__next__()\n",
    "    val_x, val_y = val_generator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "JfC9ZZm4E-Pc",
   "metadata": {
    "id": "JfC9ZZm4E-Pc"
   },
   "outputs": [],
   "source": [
    "config = model.to_json()\n",
    "with open('/content/drive/MyDrive/WINTER2022/Data40123/TBot/config.json', 'w') as fout:\n",
    "  fout.write(config)\n",
    "\n",
    "weights = model.get_weights()\n",
    "for i in range(len(weights)):\n",
    "  np.savetxt('/content/drive/MyDrive/WINTER2022/Data40123/TBot/weights_' + str(i) + '.txt', weights[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "_y7FvcvnGREY",
   "metadata": {
    "id": "_y7FvcvnGREY"
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i in range(len(weights)):\n",
    "  weights.append(np.loadtxt('/content/drive/MyDrive/WINTER2022/Data40123/TBot/weights_' + str(i) + '.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "kjNFk5FbINks",
   "metadata": {
    "id": "kjNFk5FbINks"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/WINTER2022/Data40123/TBot/config.json', 'r') as fin:\n",
    "  config = fin.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "P7kHLxCeIgGI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "P7kHLxCeIgGI",
    "outputId": "36289c02-d145-49fa-e5bf-8fa1f6347b9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_6\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 200, 130], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input_7\"}}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_11\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": true, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 30, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": {\"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}}, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}}, {\"class_name\": \"LSTM\", \"config\": {\"name\": \"lstm_12\", \"trainable\": true, \"dtype\": \"float32\", \"return_sequences\": false, \"return_state\": false, \"go_backwards\": false, \"stateful\": false, \"unroll\": false, \"time_major\": false, \"units\": 10, \"activation\": \"tanh\", \"recurrent_activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"recurrent_initializer\": {\"class_name\": \"Orthogonal\", \"config\": {\"gain\": 1.0, \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"unit_forget_bias\": true, \"kernel_regularizer\": {\"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}}, \"recurrent_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"recurrent_constraint\": null, \"bias_constraint\": null, \"dropout\": 0.0, \"recurrent_dropout\": 0.0, \"implementation\": 2}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": {\"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_15\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": {\"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_16\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": {\"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.8.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm = tf.ker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e80c97-bd2e-48f4-8a2b-bc6aa1008ca0",
   "metadata": {
    "id": "60e80c97-bd2e-48f4-8a2b-bc6aa1008ca0"
   },
   "outputs": [],
   "source": [
    "test = WP(40, 2001, 2009)\n",
    "xs = []\n",
    "ys = []\n",
    "cur_week = 0\n",
    "result = test.get_next_week()\n",
    "while result is not None:\n",
    "    print(cur_week, end=' ')\n",
    "    x, y, price, companies, b_date, s_date, cur_week = result\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "    result = test.get_next_week()\n",
    "    if cur_week > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af714392-0741-4a27-aebe-8229c7cb093f",
   "metadata": {
    "id": "af714392-0741-4a27-aebe-8229c7cb093f"
   },
   "outputs": [],
   "source": [
    "c_ys = []\n",
    "for y in ys:\n",
    "    c_ys.append(y[:, None])\n",
    "\n",
    "val_x = np.concatenate(xs, axis=0)\n",
    "val_y = np.concatenate(c_ys, axis=0)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d75ab4-be27-4a6f-afb0-a9dd08ad694c",
   "metadata": {
    "id": "19d75ab4-be27-4a6f-afb0-a9dd08ad694c"
   },
   "outputs": [],
   "source": [
    "clean_x = val_x[~(np.isnan(val_x).any(axis=2).any(axis=1))]\n",
    "clean_y = val_y[~(np.isnan(val_x).any(axis=2).any(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bfd50-22cc-4b12-b354-f39e65fb8973",
   "metadata": {
    "id": "d47bfd50-22cc-4b12-b354-f39e65fb8973"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(clean_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4356d6-89a4-416f-8362-2ee92776527b",
   "metadata": {
    "id": "0e4356d6-89a4-416f-8362-2ee92776527b"
   },
   "outputs": [],
   "source": [
    "mse = ((clean_y - pred) ** 2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad22ed2-e786-4964-b298-9cb9348650c6",
   "metadata": {
    "id": "7ad22ed2-e786-4964-b298-9cb9348650c6"
   },
   "outputs": [],
   "source": [
    "(((clean_y > 1) & (pred > 1)) | ((clean_y < 1) & (pred < 1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb64e0e-8992-414c-900b-ec1f67848548",
   "metadata": {
    "id": "cbb64e0e-8992-414c-900b-ec1f67848548"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[1, 2, 3], 'b':[4, 5, 6]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a48a1d-fd1b-4945-9984-86a053f0ffd9",
   "metadata": {
    "id": "90a48a1d-fd1b-4945-9984-86a053f0ffd9"
   },
   "outputs": [],
   "source": [
    "pd.isna(df).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf35a7-5f95-4667-a124-ec5a2088ef32",
   "metadata": {
    "id": "febf35a7-5f95-4667-a124-ec5a2088ef32"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "One_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
