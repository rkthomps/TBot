{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06a43f1-34ef-4ce6-99b7-41c1d080814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "src_path = os.path.join('..', 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "from W_Preproc import Weekly_Preprocessor as WP\n",
    "from NumTForm import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61736fc0-c72d-4287-a5f4-800c59260b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a generator from a lists of preprocessors\n",
    "Batch size represents the number of weeks, not the number of\n",
    "examples. The number of examples is much larger than the number of\n",
    "weeks. The generator randomizes over the given wps in hopes of generalizing\n",
    "over different periods of time\n",
    "'''\n",
    "def stochastic_gen(wp, weeks_in_batch):\n",
    "    num_weeks = lambda wp: (wp.end_year - wp.start_year + 1) * 52\n",
    "    rand_week = lambda num_weeks: int((np.random.random() * num_weeks) + 1)\n",
    "    n_examples = 0\n",
    "    while True:\n",
    "        n_examples = 0\n",
    "        xs = []\n",
    "        ys = []\n",
    "        while n_examples < weeks_in_batch:\n",
    "            wp.cur_week = rand_week(num_weeks(wp))\n",
    "            result = wp.get_next_week()\n",
    "            if result is not None:\n",
    "                x, y, x_names, prices, companies, b_date, s_date, cur_week = result\n",
    "                xs.append(x)\n",
    "                ys.append(y[:, None])\n",
    "                n_examples += 1\n",
    "        yield np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)[:, 0], x_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ceedd14-2bde-41e8-95a2-3897d89bf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = WP(40, 1970, 1995, binary=False)\n",
    "val = WP(40, 1996, 2005, binary=False)\n",
    "test = WP(40, 2010, 2021, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02cc3e3-e5dc-4a0a-9f27-c7aef412397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:44:06.176720: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-27 08:44:06.176981: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2538 samples, validate on 2316 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "data_generator = stochastic_gen(train, 20)\n",
    "val_generator = stochastic_gen(val, 6)\n",
    "cur_x, cur_y, x_names = data_generator.__next__()\n",
    "val_x, val_y, _ = val_generator.__next__()\n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "\n",
    "num_layers = 6\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "dff = 512\n",
    "\n",
    "tform = Transformer(\n",
    "            num_layers = num_layers,\n",
    "            d_model = d_model,\n",
    "            num_heads = num_heads,\n",
    "            dff = dff)\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "tform.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, \n",
    "                                            beta_2=0.98, epsilon=1e-9),\n",
    "        loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "for i in range(5):\n",
    "    tform.fit(cur_x, cur_y, epochs=20, batch_size=128, validation_data=(val_x, val_y))\n",
    "    pred = tform.predict(val_x)\n",
    "    print(i, pred.std())\n",
    "    del cur_x\n",
    "    del cur_y\n",
    "    del val_x\n",
    "    del val_y\n",
    "    cur_x, cur_y, _ = data_generator.__next__()\n",
    "    val_x, val_y, _ = val_generator.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc71ca7-8509-4b7b-9714-b3c6d208f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57250744],\n",
       "       [0.5725075 ],\n",
       "       [0.57250774],\n",
       "       [0.57250744],\n",
       "       [0.57250774],\n",
       "       [0.5725075 ],\n",
       "       [0.5725076 ],\n",
       "       [0.5725077 ],\n",
       "       [0.5725076 ],\n",
       "       [0.5725075 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator = stochastic_gen(train, 20)\n",
    "cur_x, _, _ = data_generator.__next__()\n",
    "model.predict(cur_x[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f8c58d-9399-4961-8bbe-912ed2ea7467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object stochastic_gen at 0x7f9d7217f3c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e886d4-0ef3-48c1-9f32-cc15df14732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2551, 200, 142), (2551,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_x.shape, cur_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a19d6ef9-6fb6-401e-a404-f27ab90f7777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2190, 200, 142), (2190,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fc82cc-7ba8-4f5c-a11f-27014efce40a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
