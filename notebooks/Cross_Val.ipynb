{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906d8bd2-44a4-472d-b822-39bd32376a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add src to path\n",
    "if not '../src' in sys.path:\n",
    "    sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97106323-1c48-4bc8-ae43-9d2354e63d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add src modules\n",
    "from W_Preproc import Weekly_Preprocessor as WP\n",
    "from W_BackTester import W_BackTester\n",
    "from Strategy import Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff069eaa-c6f7-4fb2-a8c4-30a65777e08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns an array of boundaries where i is the start of the interval\n",
    "and i + 1 is the end of the interval\n",
    "'''\n",
    "def get_cval_list(start_year, end_year, test_size):\n",
    "    years_per_segment = np.floor((end_year - start_year) * test_size)\n",
    "    return np.arange(start_year, end_year, years_per_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a306a61-25ef-4853-a5f6-ced317894c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Instantiate one preprocessor for each cval segment\n",
    "'''\n",
    "def get_wps(year_bounds):\n",
    "    WPs = []\n",
    "    for i in range(len(year_bounds) - 1):\n",
    "        WPs.append(WP(40, year_bounds[i], year_bounds[i + 1] - 1))\n",
    "    return WPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fc579cd-e48e-407c-a5f3-ae02f7d32162",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a generator from a lists of preprocessors\n",
    "Batch size represents the number of weeks, not the number of\n",
    "    examples. The number of examples is much larger than the number of\n",
    "    weeks\n",
    "'''\n",
    "def create_gen(wps, batch_size):\n",
    "    for wp in wps:\n",
    "        # Reset current week for each preprocessor\n",
    "        wp.cur_week = 1\n",
    "        \n",
    "    which_wp = lambda x: x % len(wps)\n",
    "    wp_counter = 0\n",
    "    n_examples = 0\n",
    "    while True:\n",
    "        n_examples = 0\n",
    "        xs = []\n",
    "        ys = []\n",
    "        while n_examples < batch_size:\n",
    "            result = wps[which_wp(wp_counter)].get_next_week()\n",
    "            if result is not None:\n",
    "                x, y, prices, companies, b_date, s_date, cur_week = result\n",
    "                xs.append(x)\n",
    "                ys.append(y[:, None])\n",
    "                n_examples += 1\n",
    "            else:\n",
    "                wp_counter += 1\n",
    "        yield np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed770c3a-5582-400d-bc2d-601c696d0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Trains an LSTM given a list of preprocessors\n",
    "'''\n",
    "def train_model(\n",
    "    train_wps,      \n",
    "    test_wp, \n",
    "    tr_batch_weeks = 15, \n",
    "    val_batch_weeks = 4, \n",
    "    batch_size = 1, \n",
    "    epochs = 30,\n",
    "    iters = 50):\n",
    "    \n",
    "    data_generator = create_gen(train_wps, tr_batch_weeks)\n",
    "    val_generator = create_gen([test_wp], val_batch_weeks)\n",
    "    cur_x, cur_y = data_generator.__next__()\n",
    "    val_x, val_y = val_generator.__next__()\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=cur_x.shape[1:]))\n",
    "    model.add(tf.keras.layers.LSTM(100, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1e-5)))\n",
    "    model.add(tf.keras.layers.LSTM(50, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(1e-5)))\n",
    "    model.add(tf.keras.layers.LSTM(30, kernel_regularizer=tf.keras.regularizers.l2(1e-5)))\n",
    "    model.add(tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
    "    model.add(tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
    "    model.add(tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(1e-4)))\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    for i in range(iters):\n",
    "        model.fit(cur_x, cur_y, epochs=epochs, batch_size=batch_size, validation_data=(val_x, val_y))\n",
    "        pred = model.predict(val_x)\n",
    "        print(i, pred.std())\n",
    "        del cur_x\n",
    "        del cur_y\n",
    "        del val_x\n",
    "        del val_y\n",
    "        cur_x, cur_y = data_generator.__next__()\n",
    "        val_x, val_y = val_generator.__next__()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cdf61b-e543-41ff-a496-bd04c1889b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the results by testing the performance of the model on the testing\n",
    "set, and saving the strategy results\n",
    "'''\n",
    "def get_results(model, test_wp):\n",
    "    buy_cuts = np.linspace(1, 1.1, 10)\n",
    "    sell_cuts = np.linspace(0.9, 1, 10)\n",
    "    max_alloc = np.linspace(0.05, 0.5, 10)\n",
    "    \n",
    "    strats = []\n",
    "    for b in buy_cuts:\n",
    "        for s in sell_cuts:\n",
    "            for m in max_alloc:\n",
    "                strats.append(Strategy(100000, b, s, m))\n",
    "    \n",
    "    bt = W_BackTester(\n",
    "        preprocessor = test_wp,\n",
    "        strategies = strats,\n",
    "        model = model)\n",
    "    \n",
    "    leg_mse = bt.backtest()\n",
    "    results_path = os.path.join('..', 'data_files', 'backtest_data', 'results')\n",
    "    new_path = os.path.join('..', 'data_files', 'backtest_data', 'results' + test_wp.start_year)\n",
    "    os.rename(results_path, new_path)\n",
    "    os.mkdir(results_path)\n",
    "    return leg_mse\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a98b6b1-e68d-44cb-8dfd-fac7ddeb5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create CVal WPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e822d0-f722-49a9-bcb1-bb09ad2e7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 1995\n",
    "end_year = 2006\n",
    "test_size = 0.2\n",
    "\n",
    "c_val_years = get_cval_list(start_year, end_year, test_size)\n",
    "wps = get_wps(c_val_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f773a4b-6c55-46f2-b708-3efd48619d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Validate with WPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e097a244-e7c3-4da0-950a-282b21cfef7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1995.0, 1996.0)\n",
      "(1997.0, 1998.0)\n",
      "(1999.0, 2000.0)\n",
      "(2001.0, 2002.0)\n",
      "(2003.0, 2004.0)\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-519c0562a341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_wp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_wps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_wps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_wp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_wp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d46145c42ea6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_wps, test_wp, tr_batch_weeks, val_batch_weeks, batch_size, epochs, iters)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "for wp in wps:\n",
    "    print((wp.start_year, wp.end_year))\n",
    "mses = []\n",
    "for i, wp in enumerate(wps):\n",
    "    test_wp = wps[i]\n",
    "    train_wps = wps[0:i] + wps[(i+1):]\n",
    "    model = train_model(train_wps, test_wp, iters=1)\n",
    "    mses.append(get_results(model, test_wp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9494a17-0f5c-4c1c-80aa-a5e762d36c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
